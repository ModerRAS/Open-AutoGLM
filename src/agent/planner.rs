//! Planner agent for the outer loop in dual-loop architecture.
//!
//! The Planner is responsible for:
//! - Task planning and todo list management
//! - Supervising the Executor
//! - Detecting stuck situations and intervening
//! - Managing prompt memory
//! - Handling user input

use std::collections::VecDeque;

use serde::{Deserialize, Serialize};
use serde_json::Value;

use super::executor::{ExecutorCommand, ExecutorFeedback, ExecutorStatus, ExecutorWrapper};
use super::prompt_memory::PromptMemory;
use super::todo::{TodoList, TodoStatus};
use crate::agent::AgentConfig;
use crate::model::{MessageBuilder, ModelClient, ModelConfig};

/// Configuration for the Planner agent.
#[derive(Debug, Clone)]
pub struct PlannerConfig {
    /// Model configuration for the Planner (e.g., DeepSeek).
    pub model_config: ModelConfig,
    /// Maximum number of Executor feedback entries to keep in history.
    pub max_executor_feedback_history: usize,
    /// Stuck detection threshold (consecutive unchanged screens).
    pub stuck_threshold: u32,
    /// Path to prompt memory JSON file.
    pub prompt_memory_path: Option<String>,
    /// Maximum retries for stuck situations before giving up.
    pub max_stuck_retries: u32,
    /// Whether to auto-optimize prompts after task completion.
    pub auto_optimize_prompts: bool,
    /// System prompt for the Planner model.
    pub system_prompt: Option<String>,
    /// Language for prompts ("cn" or "en").
    pub lang: String,
}

impl Default for PlannerConfig {
    fn default() -> Self {
        Self {
            model_config: ModelConfig::default(),
            max_executor_feedback_history: 2,
            stuck_threshold: 3,
            prompt_memory_path: Some("prompt_memory.json".to_string()),
            max_stuck_retries: 3,
            auto_optimize_prompts: true,
            system_prompt: None,
            lang: "cn".to_string(),
        }
    }
}

impl PlannerConfig {
    /// Set the model configuration.
    pub fn with_model_config(mut self, config: ModelConfig) -> Self {
        self.model_config = config;
        self
    }

    /// Set the max executor feedback history.
    pub fn with_max_feedback_history(mut self, max: usize) -> Self {
        self.max_executor_feedback_history = max;
        self
    }

    /// Set the stuck threshold.
    pub fn with_stuck_threshold(mut self, threshold: u32) -> Self {
        self.stuck_threshold = threshold;
        self
    }

    /// Set the prompt memory path.
    pub fn with_prompt_memory_path(mut self, path: impl Into<String>) -> Self {
        self.prompt_memory_path = Some(path.into());
        self
    }

    /// Set the system prompt.
    pub fn with_system_prompt(mut self, prompt: impl Into<String>) -> Self {
        self.system_prompt = Some(prompt.into());
        self
    }

    /// Set the language.
    pub fn with_lang(mut self, lang: impl Into<String>) -> Self {
        self.lang = lang.into();
        self
    }

    /// Get the default system prompt for Planner.
    pub fn get_system_prompt(&self) -> String {
        self.system_prompt.clone().unwrap_or_else(|| {
            if self.lang == "cn" {
                DEFAULT_PLANNER_SYSTEM_PROMPT_CN.to_string()
            } else {
                DEFAULT_PLANNER_SYSTEM_PROMPT_EN.to_string()
            }
        })
    }
}

/// Default Planner system prompt (Chinese).
pub const DEFAULT_PLANNER_SYSTEM_PROMPT_CN: &str = r#"ä½ æ˜¯ä¸€ä¸ªæ‰‹æœºè‡ªåŠ¨åŒ–ä»»åŠ¡è§„åˆ’å’Œç›‘ç£åŠ©æ‰‹ã€‚ä½ çš„èŒè´£æ˜¯å°†ç”¨æˆ·éœ€æ±‚æ‹†åˆ†æˆå­ä»»åŠ¡ï¼Œç›‘ç£æ‰§è¡Œï¼Œå¹¶åœ¨å‡ºé—®é¢˜æ—¶ä»‹å…¥ã€‚

## é‡è¦ï¼šä½ ä¸ç›´æ¥æ“ä½œæ‰‹æœº

ä½ æ˜¯è§„åˆ’è€…(Planner)ï¼Œä¸æ˜¯æ‰§è¡Œè€…(Executor)ã€‚ä½ çš„å·¥ä½œæ˜¯ï¼š
- æ‹†åˆ†ä»»åŠ¡å¹¶æ·»åŠ åˆ°ä»»åŠ¡åˆ—è¡¨
- å¯åŠ¨æ‰§è¡Œå™¨æ¥å®é™…æ“ä½œæ‰‹æœº
- ç›‘ç£æ‰§è¡Œè¿‡ç¨‹ï¼Œå¿…è¦æ—¶ç»™äºˆçº åæŒ‡å¯¼

æ‰§è¡Œå™¨(Executor)æ˜¯å¦ä¸€ä¸ª AIï¼Œå®ƒä¼šï¼š
- çœ‹æ‰‹æœºå±å¹•æˆªå›¾
- å†³å®šç‚¹å‡»ã€æ»‘åŠ¨ã€è¾“å…¥ç­‰æ“ä½œ
- è‡ªåŠ¨æ‰§è¡Œç›´åˆ°ä»»åŠ¡å®Œæˆæˆ–å¡ä½

## å·¥å…·è°ƒç”¨æ ¼å¼

**æ¯æ¬¡å›å¤åªè¾“å‡ºä¸€ä¸ª JSON å·¥å…·è°ƒç”¨ï¼Œä¸è¦ç”¨ä»£ç å—åŒ…è£¹ï¼**

### æ·»åŠ ä»»åŠ¡
{"action": "add_todo", "description": "ä»»åŠ¡æè¿°-è¦å…·ä½“æ¸…æ™°", "task_type": "ä»»åŠ¡ç±»å‹"}

**task_type æ˜¯åŠ¨æ€çš„ï¼**
- ä½ å¯ä»¥ä½¿ç”¨å·²æœ‰çš„ä»»åŠ¡ç±»å‹ï¼ˆç³»ç»Ÿä¼šæä¾›åˆ—è¡¨ï¼‰
- ä¹Ÿå¯ä»¥åˆ›å»ºæ–°çš„ä»»åŠ¡ç±»å‹ï¼ˆæè¿°æ€§çš„ä¸­æ–‡åç§°ï¼Œå¦‚ "å¾®ä¿¡èŠå¤©"ã€"æ·˜å®è´­ç‰©"ã€"åœ°å›¾å¯¼èˆª" ç­‰ï¼‰
- ç›¸ä¼¼ä»»åŠ¡ä½¿ç”¨ç›¸åŒçš„ task_typeï¼Œç³»ç»Ÿä¼šè‡ªåŠ¨å­¦ä¹ å¹¶è®°å¿†ä¼˜åŒ–æç¤ºè¯
- æ–° task_type ä¼šè¢«è‡ªåŠ¨ä¿å­˜ä¾›ä»¥åä½¿ç”¨

### å¯åŠ¨æ‰§è¡Œå™¨
{"action": "start_executor", "task_id": "task_1"}

### æš‚åœ/æ¢å¤æ‰§è¡Œå™¨
{"action": "pause_executor"}
{"action": "resume_executor"}

### æ³¨å…¥æç¤ºè¯ï¼ˆç”¨äºç»™æ‰§è¡Œå™¨çº åï¼‰
{"action": "inject_prompt", "content": "å…·ä½“çš„çº åæŒ‡å¯¼"}

ç¤ºä¾‹ï¼šå½“ç”¨æˆ·è¯´"ä½ è¦ç‚¹è¿›å»çœ‹çœ‹"æ—¶ï¼Œç”¨ inject_prompt å‘Šè¯‰æ‰§è¡Œå™¨ï¼š
{"action": "inject_prompt", "content": "ç”¨æˆ·è¦æ±‚ç‚¹å¼€å¸–å­æŸ¥çœ‹è¯¦æƒ…ï¼Œè¯·ç‚¹å‡»å½“å‰å±å¹•ä¸Šçš„ä¸€ä¸ªæœ‰è¶£å¸–å­è¿›å…¥è¯¦æƒ…é¡µ"}

### é‡ç½®æ‰§è¡Œå™¨ï¼ˆæ¸…é™¤å†å²ä¸Šä¸‹æ–‡ï¼Œé‡æ–°å¼€å§‹ï¼‰
{"action": "reset_executor"}

æ³¨æ„ï¼šé‡ç½®ä¸ä¼šæ”¹å˜ä»»åŠ¡åˆ—è¡¨ï¼Œåªæ˜¯æ¸…é™¤æ‰§è¡Œå™¨çš„å¯¹è¯å†å²ã€‚

### æ ‡è®°ä»»åŠ¡å®Œæˆ/å¤±è´¥
{"action": "complete_todo", "task_id": "task_1"}
{"action": "fail_todo", "task_id": "task_1", "reason": "å¤±è´¥åŸå› "}

### æ±‡æŠ¥è¿›åº¦
{"action": "report", "message": "æ±‡æŠ¥å†…å®¹"}

## å®Œæ•´å·¥ä½œæµç¤ºä¾‹

**ç”¨æˆ·è¯·æ±‚**: "å¸®æˆ‘æ‰“å¼€å°çº¢ä¹¦çœ‹çœ‹æœ€è¿‘çš„å¸–å­"

**ç¬¬1æ­¥**: æ·»åŠ ç¬¬ä¸€ä¸ªä»»åŠ¡
æˆ‘æ¥è§„åˆ’è¿™ä¸ªä»»åŠ¡ã€‚é¦–å…ˆéœ€è¦æ‰“å¼€å°çº¢ä¹¦ã€‚
{"action": "add_todo", "description": "æ‰“å¼€å°çº¢ä¹¦åº”ç”¨", "task_type": "å°çº¢ä¹¦æµè§ˆ"}

**ç¬¬2æ­¥**: ç³»ç»Ÿç¡®è®¤åï¼Œç»§ç»­æ·»åŠ 
ç»§ç»­æ·»åŠ æµè§ˆä»»åŠ¡ã€‚
{"action": "add_todo", "description": "æµè§ˆé¦–é¡µå¸–å­ï¼Œç‚¹å¼€å‡ ä¸ªæœ‰è¶£çš„æŸ¥çœ‹è¯¦æƒ…", "task_type": "å°çº¢ä¹¦æµè§ˆ"}

**ç¬¬3æ­¥**: ä»»åŠ¡åˆ—è¡¨å®Œæ•´ï¼Œå¯åŠ¨æ‰§è¡Œ
ä»»åŠ¡åˆ—è¡¨å·²å®Œæ•´ï¼Œç°åœ¨å¯åŠ¨æ‰§è¡Œå™¨ã€‚
{"action": "start_executor", "task_id": "task_1"}

**ç”¨æˆ·ä¸­é€”åé¦ˆ**: "ä½ è¦ç‚¹è¿›å»çœ‹çœ‹å‘€"

**å“åº”**: ç”¨ inject_prompt ç»™æ‰§è¡Œå™¨çº å
å¥½çš„ï¼Œæˆ‘æ¥å‘Šè¯‰æ‰§è¡Œå™¨éœ€è¦ç‚¹å¼€å¸–å­æŸ¥çœ‹ã€‚
{"action": "inject_prompt", "content": "ç”¨æˆ·è¦æ±‚ç‚¹å¼€å¸–å­æŸ¥çœ‹è¯¦æƒ…ï¼Œè¯·ç‚¹å‡»å½“å‰å±å¹•ä¸Šæœ€æœ‰è¶£æˆ–çƒ­é—¨çš„ä¸€ä¸ªå¸–å­è¿›å…¥è¯¦æƒ…é¡µï¼Œé˜…è¯»å†…å®¹åå†è¿”å›"}

## å…³é”®è§„åˆ™

1. **æ¯æ¬¡åªè¾“å‡ºä¸€ä¸ª JSON**ï¼Œç­‰å¾…ç³»ç»Ÿåé¦ˆåå†è¿›è¡Œä¸‹ä¸€æ­¥
2. **ä¸è¦ç”¨ä»£ç å—**ï¼Œç›´æ¥è¾“å‡º JSON å¯¹è±¡
3. **ä»»åŠ¡æè¿°è¦å…·ä½“**ï¼ŒåŒ…å«æ¸…æ™°çš„æ“ä½œæŒ‡å¯¼
4. **ç”¨æˆ·ä¸­é€”åé¦ˆæ—¶**ï¼Œä½¿ç”¨ inject_prompt è€Œä¸æ˜¯æ·»åŠ æ–°ä»»åŠ¡
5. **reset_executor åªæ¸…é™¤å¯¹è¯å†å²**ï¼Œä¸ä¼šå½±å“ä»»åŠ¡åˆ—è¡¨
6. **task_type è¦æœ‰æè¿°æ€§**ï¼Œæ–¹ä¾¿ç³»ç»Ÿå­¦ä¹ å’Œå¤ç”¨è®°å¿†"#;

/// Default Planner system prompt (English).
pub const DEFAULT_PLANNER_SYSTEM_PROMPT_EN: &str = r#"You are a phone automation task planning and supervision assistant. Your job is to break down user requests into sub-tasks, supervise execution, and intervene when needed.

## Tool Call Format

You must use JSON format to call tools. Only call one tool per response. Format:

### Add Task
```json
{"action": "add_todo", "description": "Task description", "task_type": "task_type"}
```
task_type options: "wechat", "xiaohongshu", "douyin", "system", "general"

### Start Executor
```json
{"action": "start_executor", "task_id": "task_id"}
```
task_id is auto-generated after add_todo, format: "task_1", "task_2", etc.

### Pause/Resume Executor
```json
{"action": "pause_executor"}
{"action": "resume_executor"}
```

### Inject Prompt (correction)
```json
{"action": "inject_prompt", "content": "prompt content"}
```

### Reset Executor
```json
{"action": "reset_executor"}
```

### Mark Task Complete/Failed
```json
{"action": "complete_todo", "task_id": "task_id"}
{"action": "fail_todo", "task_id": "task_id", "reason": "failure reason"}
```

### Report Progress (no action)
```json
{"action": "report", "message": "report content"}
```

### Wait
```json
{"action": "wait"}
```

## Workflow

1. After receiving user request, use add_todo to add all sub-tasks
2. Then use start_executor to start the first task
3. Monitor execution feedback, use inject_prompt to correct if needed
4. Next task starts automatically after completion

## Important Rules

- Output only one JSON tool call per response
- Briefly explain your thinking, then output JSON
- Do not use code blocks, output JSON object directly
- When receiving user request, first add the first task, wait for confirmation, then add next or start execution"#;

/// Planner action types.
#[derive(Debug, Clone, Serialize, Deserialize)]
#[serde(tag = "action", rename_all = "snake_case")]
pub enum PlannerAction {
    /// Add a new todo item.
    AddTodo {
        description: String,
        task_type: String,
    },
    /// Start the executor on a task.
    StartExecutor { task_id: String },
    /// Pause the executor.
    PauseExecutor,
    /// Resume the executor.
    ResumeExecutor,
    /// Inject a prompt into executor.
    InjectPrompt { content: String },
    /// Reset executor context.
    ResetExecutor,
    /// Mark a todo as complete.
    CompleteTodo { task_id: String },
    /// Mark a todo as failed.
    FailTodo { task_id: String, reason: String },
    /// Report to user (no action, just message).
    Report { message: String },
    /// Wait for more information.
    Wait,
    /// Task planning complete.
    Done { message: String },
}

/// Planner agent for the outer loop.
pub struct PlannerAgent {
    /// Model client for Planner.
    model_client: ModelClient,
    /// Planner configuration.
    config: PlannerConfig,
    /// Todo task list.
    todo_list: TodoList,
    /// Executor instance.
    executor: ExecutorWrapper,
    /// Executor model config (for recreating).
    executor_model_config: ModelConfig,
    /// Executor agent config (for recreating).
    executor_agent_config: AgentConfig,
    /// Limited history of Executor feedback.
    executor_feedback_history: VecDeque<ExecutorFeedback>,
    /// User input queue.
    user_input_queue: VecDeque<String>,
    /// Planner's own conversation context.
    context: Vec<Value>,
    /// Prompt memory for optimized prompts.
    prompt_memory: PromptMemory,
    /// Consecutive stuck count (for multi-stuck handling).
    consecutive_stuck_count: u32,
    /// Execution log for prompt optimization.
    execution_log: Vec<String>,
    /// Whether the planner is running.
    is_running: bool,
    /// Task types pending consolidation (accumulated corrections).
    pending_consolidation_task_types: Vec<String>,
}

impl PlannerAgent {
    /// Create a new PlannerAgent.
    pub fn new(
        planner_config: PlannerConfig,
        executor_model_config: ModelConfig,
        executor_agent_config: AgentConfig,
    ) -> Self {
        let model_client = ModelClient::new(planner_config.model_config.clone());

        // Load prompt memory if path specified
        let prompt_memory = planner_config
            .prompt_memory_path
            .as_ref()
            .and_then(|path| PromptMemory::load(path).ok())
            .unwrap_or_default();

        let executor =
            ExecutorWrapper::new(executor_model_config.clone(), executor_agent_config.clone())
                .with_stuck_threshold(planner_config.stuck_threshold);

        Self {
            model_client,
            config: planner_config,
            todo_list: TodoList::new(),
            executor,
            executor_model_config,
            executor_agent_config,
            executor_feedback_history: VecDeque::new(),
            user_input_queue: VecDeque::new(),
            context: Vec::new(),
            prompt_memory,
            consecutive_stuck_count: 0,
            execution_log: Vec::new(),
            is_running: false,
            pending_consolidation_task_types: Vec::new(),
        }
    }

    /// Queue user input for processing.
    pub fn queue_user_input(&mut self, input: String) {
        self.user_input_queue.push_back(input);
    }

    /// Check if there's pending user input.
    pub fn has_pending_input(&self) -> bool {
        !self.user_input_queue.is_empty()
    }

    /// Get the todo list.
    pub fn todo_list(&self) -> &TodoList {
        &self.todo_list
    }

    /// Get mutable todo list.
    pub fn todo_list_mut(&mut self) -> &mut TodoList {
        &mut self.todo_list
    }

    /// Get executor status.
    pub fn executor_status(&self) -> &ExecutorStatus {
        self.executor.status()
    }

    /// Check if planner is running.
    pub fn is_running(&self) -> bool {
        self.is_running
    }

    /// Start the planner.
    pub fn start(&mut self) {
        self.is_running = true;
        self.initialize_context();
    }

    /// Stop the planner.
    pub fn stop(&mut self) {
        self.is_running = false;
        self.executor.enqueue(ExecutorCommand::Stop);
    }

    /// Initialize planner context with system prompt and available task types.
    fn initialize_context(&mut self) {
        self.context.clear();

        // Build system prompt with available task types
        let base_prompt = self.config.get_system_prompt();
        let task_types_summary = self.prompt_memory.get_task_types_summary();

        let full_prompt = format!(
            "{}\n\n## å·²ä¿å­˜çš„ä»»åŠ¡ç±»å‹è®°å¿†\n\nä»¥ä¸‹æ˜¯ç³»ç»Ÿå·²å­¦ä¹ çš„ä»»åŠ¡ç±»å‹ï¼Œä¼˜å…ˆä½¿ç”¨è¿™äº›ç±»å‹ä»¥ä¾¿å¤ç”¨è®°å¿†ï¼š\n\n{}\n\nä½ ä¹Ÿå¯ä»¥åˆ›å»ºæ–°çš„ä»»åŠ¡ç±»å‹ï¼Œç³»ç»Ÿä¼šè‡ªåŠ¨å­¦ä¹ ã€‚",
            base_prompt,
            task_types_summary
        );

        self.context
            .push(MessageBuilder::create_system_message(&full_prompt));
    }

    /// Refresh the system context with updated task types.
    /// Call this when task types change significantly.
    pub fn refresh_context_with_task_types(&mut self) {
        if !self.context.is_empty() {
            // Update the system message (first message)
            let base_prompt = self.config.get_system_prompt();
            let task_types_summary = self.prompt_memory.get_task_types_summary();

            let full_prompt = format!(
                "{}\n\n## å·²ä¿å­˜çš„ä»»åŠ¡ç±»å‹è®°å¿†\n\nä»¥ä¸‹æ˜¯ç³»ç»Ÿå·²å­¦ä¹ çš„ä»»åŠ¡ç±»å‹ï¼Œä¼˜å…ˆä½¿ç”¨è¿™äº›ç±»å‹ä»¥ä¾¿å¤ç”¨è®°å¿†ï¼š\n\n{}\n\nä½ ä¹Ÿå¯ä»¥åˆ›å»ºæ–°çš„ä»»åŠ¡ç±»å‹ï¼Œç³»ç»Ÿä¼šè‡ªåŠ¨å­¦ä¹ ã€‚",
                base_prompt,
                task_types_summary
            );

            self.context[0] = MessageBuilder::create_system_message(&full_prompt);
        }
    }

    /// Execute one tick of the Executor loop.
    /// Call this in the Executor's dedicated loop.
    pub async fn tick_executor(&mut self) -> ExecutorFeedback {
        let feedback = self.executor.tick().await;
        self.collect_executor_feedback(feedback.clone());
        feedback
    }

    /// Execute one tick of the Planner loop.
    /// Returns true if the planner should continue running.
    pub async fn tick_planner(&mut self) -> bool {
        if !self.is_running {
            return false;
        }

        // 1. Process any pending consolidations (corrections -> optimized prompts)
        self.process_pending_consolidations().await;

        // 2. Process any pending user input
        self.process_user_input().await;

        // 3. Supervise executor and decide actions
        self.supervise_executor().await;

        // 4. Check if we should continue
        !self.todo_list.is_all_done() || self.has_pending_input()
    }

    /// Process pending user input.
    async fn process_user_input(&mut self) {
        while let Some(input) = self.user_input_queue.pop_front() {
            println!("\nğŸ§  [Planner] Processing user input: {}", input);
            tracing::info!("Processing user input: {}", input);

            // Build executor status to include with user input
            let executor_status_summary = self.build_executor_status_summary();
            let todo_summary = self.build_todo_summary();

            // Add user message along with current executor state
            let enriched_input = format!(
                "[ç”¨æˆ·è¾“å…¥]\n{}\n\n[å½“å‰æ‰§è¡Œå™¨çŠ¶æ€]\n{}\n\n[å½“å‰ä»»åŠ¡åˆ—è¡¨]\n{}",
                input, executor_status_summary, todo_summary
            );
            self.context
                .push(MessageBuilder::create_user_message(&enriched_input, None));

            // Continue conversation until planner stops adding tasks or starts executor
            self.continue_planner_conversation().await;
        }
    }

    /// Continue the planner conversation loop until a stopping condition.
    /// This allows the planner to add multiple tasks and then start execution.
    async fn continue_planner_conversation(&mut self) {
        let max_turns = 20; // Safety limit
        let mut turns = 0;

        loop {
            turns += 1;
            if turns > max_turns {
                println!("âš ï¸ [System] è¾¾åˆ°æœ€å¤§å¯¹è¯è½®æ•°é™åˆ¶");
                break;
            }

            // Get planner's response
            match self.get_planner_response().await {
                Some((response_text, action)) => {
                    // Print DeepSeek's response to terminal
                    println!("\nğŸ’¬ [DeepSeek Response]:");
                    println!("{}", response_text);
                    println!();

                    // Execute the parsed action
                    if let Some(action) = action {
                        println!("ğŸ“‹ [Action]: {:?}", action);

                        // Check if this is a terminal action that should stop the loop
                        let should_continue = self.should_continue_after_action(&action);

                        self.execute_planner_action(action).await;

                        if !should_continue {
                            break;
                        }

                        // After executing action, prompt the model to continue
                        // (The feedback was already added in execute_planner_action)
                    } else {
                        // No valid action parsed, stop
                        println!("âš ï¸ [System] æœªèƒ½è§£ææœ‰æ•ˆåŠ¨ä½œ");
                        break;
                    }
                }
                None => {
                    println!("âŒ [Planner] Failed to get response from model");
                    break;
                }
            }
        }
    }

    /// Determine if the conversation should continue after an action.
    fn should_continue_after_action(&self, action: &PlannerAction) -> bool {
        match action {
            // After adding a task, continue to add more or start executor
            PlannerAction::AddTodo { .. } => true,
            // After starting executor, stop the conversation loop
            PlannerAction::StartExecutor { .. } => false,
            // Report and wait can continue
            PlannerAction::Report { .. } => true,
            PlannerAction::Wait => false,
            // Done means planning is complete
            PlannerAction::Done { .. } => false,
            // Other actions stop the loop
            _ => false,
        }
    }

    /// Get planner's response and parse action.
    /// Returns (raw_response, parsed_action).
    async fn get_planner_response(&mut self) -> Option<(String, Option<PlannerAction>)> {
        // Call planner model
        match self.model_client.request(&self.context).await {
            Ok(response) => {
                let response_text = response.raw_content.clone();

                // Add assistant response to context
                self.context
                    .push(MessageBuilder::create_assistant_message(&response.action));

                // Parse action from response
                let action = self.parse_planner_action(&response.action);
                Some((response_text, action))
            }
            Err(e) => {
                println!("âŒ [Planner] Model error: {}", e);
                tracing::error!("Planner model error: {}", e);
                None
            }
        }
    }

    /// Supervise executor and handle stuck/completion.
    async fn supervise_executor(&mut self) {
        // Check latest executor feedback - clone to avoid borrow issues
        let feedback_info = self.executor_feedback_history.back().map(|f| {
            (
                f.status.clone(),
                f.context_overflow_detected,
                f.consecutive_parse_errors,
                f.clone(),
            )
        });

        if let Some((status, context_overflow, parse_errors, _feedback)) = feedback_info {
            // Handle context overflow first (highest priority)
            if context_overflow {
                self.handle_context_overflow(parse_errors).await;
                return;
            }

            match status {
                ExecutorStatus::Stuck => {
                    self.handle_stuck().await;
                }
                ExecutorStatus::Completed => {
                    self.handle_executor_completed().await;
                }
                ExecutorStatus::Failed(reason) => {
                    self.handle_executor_failed(reason).await;
                }
                _ => {
                    // Running, Paused, or Idle - nothing special to do
                    self.consecutive_stuck_count = 0;
                }
            }
        }
    }

    /// Handle context overflow (too many parse errors).
    async fn handle_context_overflow(&mut self, parse_errors: u32) {
        println!(
            "âš ï¸ [System] æ£€æµ‹åˆ°æ‰§è¡Œå™¨ä¸Šä¸‹æ–‡æº¢å‡º (è¿ç»­ {} æ¬¡è§£æé”™è¯¯)",
            parse_errors
        );
        println!("   ğŸ”„ è‡ªåŠ¨é‡ç½®æ‰§è¡Œå™¨ä¸Šä¸‹æ–‡å¹¶é‡è¯•å½“å‰ä»»åŠ¡...");
        tracing::error!(
            "Context overflow detected: {} consecutive parse errors",
            parse_errors
        );

        // Get current task info before reset
        let current_task_info = self
            .todo_list
            .current_running()
            .map(|t| (t.id.clone(), t.description.clone(), t.task_type.clone()));

        // Reset executor context
        self.executor.enqueue(ExecutorCommand::ResetContext);

        // If there's a current task, restart it
        if let Some((task_id, task_desc, _task_type)) = current_task_info {
            println!("   ğŸ“‹ é‡æ–°å¯åŠ¨ä»»åŠ¡: {} - {}", task_id, task_desc);

            // Small delay to let reset take effect
            tokio::time::sleep(tokio::time::Duration::from_millis(100)).await;

            // Restart the task
            self.start_task(&task_id);
        } else {
            // No current task, check if there are pending tasks
            if let Some(next_task) = self.todo_list.next_pending() {
                let task_id = next_task.id.clone();
                println!("   ğŸ“‹ å¯åŠ¨ä¸‹ä¸€ä¸ªå¾…æ‰§è¡Œä»»åŠ¡: {}", task_id);
                self.start_task(&task_id);
            }
        }
    }

    /// Handle stuck executor.
    async fn handle_stuck(&mut self) {
        self.consecutive_stuck_count += 1;
        tracing::warn!(
            "Executor stuck (consecutive count: {})",
            self.consecutive_stuck_count
        );

        // Log for prompt optimization
        self.execution_log.push(format!(
            "[STUCK] Consecutive stuck count: {}",
            self.consecutive_stuck_count
        ));

        if self.consecutive_stuck_count >= self.config.max_stuck_retries {
            // Too many stuck attempts, consider resetting
            tracing::warn!("Max stuck retries reached, resetting executor");
            self.executor.enqueue(ExecutorCommand::ResetContext);

            // Mark current task as needing retry
            if let Some(task) = self.todo_list.current_running() {
                let task_id = task.id.clone();
                if let Some(task) = self.todo_list.get_mut(&task_id) {
                    if !task.retry() {
                        tracing::error!("Task {} failed after max retries", task_id);
                    }
                }
            }

            self.consecutive_stuck_count = 0;
        } else {
            // Generate correction prompt
            let correction = self.generate_correction_prompt().await;
            self.executor.enqueue(ExecutorCommand::InjectPrompt {
                content: correction,
            });
        }
    }

    /// Handle executor completion.
    async fn handle_executor_completed(&mut self) {
        tracing::info!("Executor completed task");

        // Mark current todo as done
        if let Some(task) = self.todo_list.current_running() {
            let task_id = task.id.clone();
            let task_type = task.task_type.clone();

            if let Some(task) = self.todo_list.get_mut(&task_id) {
                task.complete();
            }

            // Record success in prompt memory
            self.prompt_memory.record_usage(&task_type, true);

            // Save prompt memory
            if let Some(path) = &self.config.prompt_memory_path {
                let _ = self.prompt_memory.save(path);
            }
        }

        // Check if there are more tasks
        if let Some(next_task) = self.todo_list.next_pending() {
            let task_id = next_task.id.clone();
            self.start_task(&task_id);
        }
    }

    /// Handle executor failure.
    async fn handle_executor_failed(&mut self, reason: String) {
        tracing::error!("Executor failed: {}", reason);

        // Log for prompt optimization
        self.execution_log.push(format!("[FAILED] {}", reason));

        // Mark current todo as failed or retry
        if let Some(task) = self.todo_list.current_running() {
            let task_id = task.id.clone();
            let task_type = task.task_type.clone();

            if let Some(task) = self.todo_list.get_mut(&task_id) {
                if task.can_retry() {
                    task.retry();
                    // Retry the task
                    self.start_task(&task_id);
                } else {
                    task.fail(&reason);

                    // Record failure in prompt memory
                    self.prompt_memory.record_usage(&task_type, false);

                    // Try to optimize prompt if enabled
                    if self.config.auto_optimize_prompts {
                        self.optimize_prompt(&task_type).await;
                    }

                    // Move to next task
                    if let Some(next_task) = self.todo_list.next_pending() {
                        let next_id = next_task.id.clone();
                        self.start_task(&next_id);
                    }
                }
            }
        }
    }

    /// Start executing a task.
    fn start_task(&mut self, task_id: &str) {
        if let Some(task) = self.todo_list.get_mut(task_id) {
            task.start();

            // Get system prompt from memory if available
            let system_prompt = self
                .prompt_memory
                .get_prompt(&task.task_type)
                .map(|s| s.to_string());

            self.executor.enqueue(ExecutorCommand::StartTask {
                task_id: task.id.clone(),
                description: task.description.clone(),
                system_prompt,
            });

            tracing::info!("Started task: {} - {}", task.id, task.description);
        }
    }

    /// Generate a correction prompt for stuck situations.
    async fn generate_correction_prompt(&self) -> String {
        // Build context about what happened
        let recent_feedback: Vec<_> = self.executor_feedback_history.iter().collect();

        let feedback_summary = recent_feedback
            .iter()
            .map(|f| {
                format!(
                    "Step {}: status={:?}, screen_changed={}",
                    f.step_count, f.status, f.screen_changed
                )
            })
            .collect::<Vec<_>>()
            .join("\n");

        // Simple correction prompt (could be enhanced with model call)
        if self.config.lang == "cn" {
            format!(
                "æ‰§è¡Œä¼¼ä¹å¡ä½äº†ã€‚æœ€è¿‘çŠ¶æ€ï¼š\n{}\n\nè¯·å°è¯•ä¸åŒçš„æ–¹æ³•ï¼š\n\
                1. å¦‚æœæŒ‰é’®æ— æ³•ç‚¹å‡»ï¼Œå°è¯•æ»‘åŠ¨å±å¹•\n\
                2. å¦‚æœé¡µé¢æ²¡æœ‰å“åº”ï¼Œå°è¯•è¿”å›ä¸Šä¸€çº§\n\
                3. å¦‚æœæ“ä½œä½ç½®ä¸æ­£ç¡®ï¼Œä»”ç»†è§‚å¯Ÿç•Œé¢å…ƒç´ ä½ç½®\n\
                è¯·ç»§ç»­æ‰§è¡Œä»»åŠ¡ã€‚",
                feedback_summary
            )
        } else {
            format!(
                "Execution seems stuck. Recent status:\n{}\n\n\
                Please try a different approach:\n\
                1. If button won't click, try scrolling\n\
                2. If page not responding, try going back\n\
                3. If position incorrect, carefully observe element positions\n\
                Please continue the task.",
                feedback_summary
            )
        }
    }

    /// Optimize prompt based on execution log.
    async fn optimize_prompt(&mut self, task_type: &str) {
        if self.execution_log.is_empty() {
            return;
        }

        let log_summary = self.execution_log.join("\n");

        // Build optimization request
        let request = if self.config.lang == "cn" {
            format!(
                "ä»»åŠ¡ç±»å‹: {}\n\næ‰§è¡Œæ—¥å¿—:\n{}\n\n\
                è¯·æ ¹æ®æ‰§è¡Œä¸­é‡åˆ°çš„é—®é¢˜ï¼Œç”Ÿæˆä¸€ä¸ªä¼˜åŒ–åçš„ç³»ç»Ÿæç¤ºè¯ï¼Œ\
                å¸®åŠ©æœªæ¥æ‰§è¡ŒåŒç±»ä»»åŠ¡æ—¶é¿å…è¿™äº›é—®é¢˜ã€‚\
                åªè¾“å‡ºä¼˜åŒ–åçš„æç¤ºè¯å†…å®¹ï¼Œä¸è¦å…¶ä»–è§£é‡Šã€‚",
                task_type, log_summary
            )
        } else {
            format!(
                "Task type: {}\n\nExecution log:\n{}\n\n\
                Based on the issues encountered, generate an optimized system prompt \
                to help avoid these problems in future executions of similar tasks.\
                Only output the optimized prompt content, no explanations.",
                task_type, log_summary
            )
        };

        // Request optimization from planner model
        let messages = vec![
            MessageBuilder::create_system_message("You are a prompt optimization assistant."),
            MessageBuilder::create_user_message(&request, None),
        ];

        if let Ok(response) = self.model_client.request(&messages).await {
            let optimized_prompt = response.action.trim().to_string();
            if !optimized_prompt.is_empty() {
                self.prompt_memory.update(task_type, &optimized_prompt);
                if let Some(path) = &self.config.prompt_memory_path {
                    let _ = self.prompt_memory.save(path);
                }
                tracing::info!("Optimized prompt for task type: {}", task_type);
            }
        }

        // Clear execution log
        self.execution_log.clear();
    }

    /// Consolidate user corrections into an optimized prompt.
    /// This is called when enough corrections accumulate for a task type.
    async fn consolidate_corrections(&mut self, task_type: &str) {
        let corrections_summary = match self.prompt_memory.get_corrections_summary(task_type) {
            Some(s) if !s.is_empty() => s,
            _ => return,
        };

        let current_prompt = self
            .prompt_memory
            .get_prompt(task_type)
            .unwrap_or("")
            .to_string();

        println!("ğŸ“š [System] æ­£åœ¨æ•´åˆ {} çš„ç”¨æˆ·çº åè®°å½•...", task_type);

        let request = if self.config.lang == "cn" {
            format!(
                "ä»»åŠ¡ç±»å‹: {}\n\nå½“å‰ç³»ç»Ÿæç¤ºè¯:\n{}\n\nç”¨æˆ·çº åè®°å½•:\n{}\n\n\
                è¯·æ ¹æ®ç”¨æˆ·çš„çº åè®°å½•ï¼Œç”Ÿæˆä¸€ä¸ªä¼˜åŒ–åçš„ç³»ç»Ÿæç¤ºè¯ã€‚\n\
                è¿™ä¸ªæç¤ºè¯åº”è¯¥åŒ…å«ç”¨æˆ·åå¤å¼ºè°ƒçš„æ“ä½œè§„èŒƒå’Œæ³¨æ„äº‹é¡¹ã€‚\n\
                ç¡®ä¿æ–°çš„æç¤ºè¯ç®€æ´æ˜äº†ï¼Œèƒ½å¤Ÿå¸®åŠ©æ‰§è¡Œå™¨åœ¨æœªæ¥é¿å…åŒæ ·çš„é”™è¯¯ã€‚\n\
                åªè¾“å‡ºä¼˜åŒ–åçš„æç¤ºè¯å†…å®¹ï¼Œä¸è¦å…¶ä»–è§£é‡Šã€‚",
                task_type,
                if current_prompt.is_empty() {
                    "(æ— )"
                } else {
                    &current_prompt
                },
                corrections_summary
            )
        } else {
            format!(
                "Task type: {}\n\nCurrent system prompt:\n{}\n\nUser corrections:\n{}\n\n\
                Based on user corrections, generate an optimized system prompt.\n\
                Include the operational guidelines that users have repeatedly emphasized.\n\
                Ensure the new prompt is concise and helps the executor avoid similar mistakes.\n\
                Only output the optimized prompt content, no explanations.",
                task_type,
                if current_prompt.is_empty() {
                    "(none)"
                } else {
                    &current_prompt
                },
                corrections_summary
            )
        };

        // Request optimization from planner model
        let messages = vec![
            MessageBuilder::create_system_message("You are a prompt optimization assistant. Generate concise, actionable system prompts."),
            MessageBuilder::create_user_message(&request, None),
        ];

        if let Ok(response) = self.model_client.request(&messages).await {
            let optimized_prompt = response.action.trim().to_string();
            if !optimized_prompt.is_empty() {
                // Update the prompt
                self.prompt_memory.update(task_type, &optimized_prompt);

                // Clear corrections after consolidation
                if let Some(entry) = self.prompt_memory.get_mut(task_type) {
                    entry.clear_corrections();
                }

                if let Some(path) = &self.config.prompt_memory_path {
                    let _ = self.prompt_memory.save(path);
                }

                println!("âœ… [System] å·²æ•´åˆç”¨æˆ·çº ååˆ°è®°å¿†: {}", task_type);
                // Safe truncation for display (handle UTF-8 properly)
                let display_prompt = if optimized_prompt.chars().count() > 80 {
                    format!(
                        "{}...",
                        optimized_prompt.chars().take(80).collect::<String>()
                    )
                } else {
                    optimized_prompt.clone()
                };
                println!("ğŸ“ æ–°æç¤ºè¯: {}", display_prompt);
                tracing::info!("Consolidated corrections for task type: {}", task_type);

                // Refresh context so Planner knows about updated task types
                self.refresh_context_with_task_types();
            }
        }
    }

    /// Process any pending consolidation tasks.
    pub async fn process_pending_consolidations(&mut self) {
        let task_types: Vec<String> = self.pending_consolidation_task_types.drain(..).collect();
        for task_type in task_types {
            self.consolidate_corrections(&task_type).await;
        }
    }

    /// Get planner's decision based on current context.
    /// Used by supervise_executor (no need to print response again).
    async fn get_planner_decision(&mut self) -> Option<PlannerAction> {
        // Add executor status summary to context
        let status_summary = self.build_executor_status_summary();
        let todo_summary = self.build_todo_summary();

        let context_update = format!(
            "[å½“å‰çŠ¶æ€]\n{}\n\n[ä»»åŠ¡åˆ—è¡¨]\n{}\n\nè¯·å†³å®šä¸‹ä¸€æ­¥æ“ä½œã€‚",
            status_summary, todo_summary
        );

        // Add as a system message update
        self.context
            .push(MessageBuilder::create_user_message(&context_update, None));

        // Call planner model
        match self.model_client.request(&self.context).await {
            Ok(response) => {
                // Print response for debugging
                println!("\nğŸ§  [Planner Supervision Response]:");
                println!("{}", response.raw_content);
                println!();

                // Add assistant response to context
                self.context
                    .push(MessageBuilder::create_assistant_message(&response.action));

                // Parse action from response
                self.parse_planner_action(&response.action)
            }
            Err(e) => {
                println!("âŒ [Planner] Model error: {}", e);
                tracing::error!("Planner model error: {}", e);
                None
            }
        }
    }

    /// Build executor status summary.
    fn build_executor_status_summary(&self) -> String {
        let status = self.executor.status();
        let step_count = self.executor.step_count();

        let mut summary = format!("ExecutorçŠ¶æ€: {:?}\næ­¥éª¤æ•°: {}\n", status, step_count);

        // Add recent feedback with full details
        if !self.executor_feedback_history.is_empty() {
            summary.push_str("\n=== æ‰§è¡Œå™¨æœ€è¿‘è¾“å‡º ===\n");
            for (i, feedback) in self.executor_feedback_history.iter().enumerate() {
                summary.push_str(&format!(
                    "\n--- ç¬¬{}æ¡åé¦ˆ (step={}, å±å¹•å˜åŒ–={}) ---\n",
                    i + 1,
                    feedback.step_count,
                    if feedback.screen_changed {
                        "æ˜¯"
                    } else {
                        "å¦"
                    }
                ));

                if let Some(ref result) = feedback.last_result {
                    // Include thinking (æ‰§è¡Œå™¨çš„æ€è€ƒè¿‡ç¨‹)
                    if !result.thinking.is_empty() {
                        summary.push_str(&format!("ğŸ’­ æ€è€ƒè¿‡ç¨‹:\n{}\n", result.thinking));
                    }

                    // Include action type
                    if let Some(ref action_type) = result.action_type {
                        summary.push_str(&format!("ğŸ¯ æ‰§è¡ŒåŠ¨ä½œ: {}\n", action_type));
                    }

                    // Include message if any
                    if let Some(ref msg) = result.message {
                        summary.push_str(&format!("ğŸ’¬ æ¶ˆæ¯: {}\n", msg));
                    }

                    // Include success/finished status
                    summary.push_str(&format!(
                        "çŠ¶æ€: success={}, finished={}\n",
                        result.success, result.finished
                    ));
                }
            }
            summary.push_str("=== æ‰§è¡Œå™¨è¾“å‡ºç»“æŸ ===\n");
        }

        summary
    }

    /// Build todo list summary.
    fn build_todo_summary(&self) -> String {
        let stats = self.todo_list.stats();
        let mut summary = format!(
            "æ€»ä»»åŠ¡: {} | å¾…æ‰§è¡Œ: {} | æ‰§è¡Œä¸­: {} | å®Œæˆ: {} | å¤±è´¥: {}\n\n",
            stats.total, stats.pending, stats.running, stats.done, stats.failed
        );

        for item in self.todo_list.items() {
            let status_icon = match item.status {
                TodoStatus::Pending => "â³",
                TodoStatus::Running => "ğŸ”„",
                TodoStatus::Done => "âœ…",
                TodoStatus::Failed => "âŒ",
                TodoStatus::Skipped => "â­ï¸",
            };
            summary.push_str(&format!(
                "{} [{}] {} (ç±»å‹: {})\n",
                status_icon, item.id, item.description, item.task_type
            ));
        }

        summary
    }

    /// Parse planner action from model response.
    fn parse_planner_action(&self, response: &str) -> Option<PlannerAction> {
        // Try to parse as JSON directly
        if let Ok(action) = serde_json::from_str::<PlannerAction>(response) {
            return Some(action);
        }

        // Try to extract JSON from code block (```json ... ``` or ``` ... ```)
        let json_str = self.extract_json_from_response(response);
        if let Some(json) = json_str {
            if let Ok(action) = serde_json::from_str::<PlannerAction>(&json) {
                return Some(action);
            }
        }

        // Try to find the FIRST complete JSON object in the response
        // This handles cases where Planner outputs multiple JSONs
        if let Some(json_str) = self.extract_first_json_object(response) {
            if let Ok(action) = serde_json::from_str::<PlannerAction>(&json_str) {
                return Some(action);
            }
        }

        // Simple keyword-based parsing as fallback
        let lower = response.to_lowercase();
        if lower.contains("wait") || lower.contains("ç­‰å¾…") {
            Some(PlannerAction::Wait)
        } else if lower.contains("done") || lower.contains("å®Œæˆ") {
            Some(PlannerAction::Done {
                message: response.to_string(),
            })
        } else {
            Some(PlannerAction::Report {
                message: response.to_string(),
            })
        }
    }

    /// Extract the first complete JSON object from text.
    /// Uses brace counting to find matching pairs.
    fn extract_first_json_object(&self, text: &str) -> Option<String> {
        let start = text.find('{')?;
        let chars: Vec<char> = text[start..].chars().collect();

        let mut brace_count = 0;
        let mut in_string = false;
        let mut escape_next = false;

        for (i, ch) in chars.iter().enumerate() {
            if escape_next {
                escape_next = false;
                continue;
            }

            match ch {
                '\\' if in_string => {
                    escape_next = true;
                }
                '"' => {
                    in_string = !in_string;
                }
                '{' if !in_string => {
                    brace_count += 1;
                }
                '}' if !in_string => {
                    brace_count -= 1;
                    if brace_count == 0 {
                        // Found the end of the first complete JSON object
                        return Some(chars[..=i].iter().collect());
                    }
                }
                _ => {}
            }
        }

        None
    }

    /// Extract JSON from markdown code blocks or bare JSON.
    fn extract_json_from_response(&self, response: &str) -> Option<String> {
        // Pattern 1: ```json\n{...}\n```
        if let Some(start) = response.find("```json") {
            let after_marker = &response[start + 7..];
            if let Some(end) = after_marker.find("```") {
                let json_part = after_marker[..end].trim();
                return Some(json_part.to_string());
            }
        }

        // Pattern 2: ```\n{...}\n```
        if let Some(start) = response.find("```\n{") {
            let after_marker = &response[start + 4..];
            if let Some(end) = after_marker.find("```") {
                let json_part = after_marker[..end].trim();
                return Some(json_part.to_string());
            }
        }

        // Pattern 3: ```{...}```
        if let Some(start) = response.find("```{") {
            let after_marker = &response[start + 3..];
            if let Some(end) = after_marker.find("```") {
                let json_part = after_marker[..end].trim();
                return Some(json_part.to_string());
            }
        }

        None
    }

    /// Execute a planner action.
    async fn execute_planner_action(&mut self, action: PlannerAction) {
        match action {
            PlannerAction::AddTodo {
                description,
                task_type,
            } => {
                let task_id = self.todo_list.add(&description, &task_type);
                println!(
                    "âœ… [System] å·²æ·»åŠ ä»»åŠ¡: {} (ID: {}, ç±»å‹: {})",
                    description, task_id, task_type
                );
                tracing::info!(
                    "Added todo: {} (id: {}, type: {})",
                    description,
                    task_id,
                    task_type
                );

                // Add system feedback with clear next step instructions
                let feedback = format!(
                    "[ç³»ç»Ÿåé¦ˆ] ä»»åŠ¡å·²æ·»åŠ æˆåŠŸã€‚\n\
                    - ID: {}\n\
                    - æè¿°: {}\n\
                    - ç±»å‹: {}\n\n\
                    å½“å‰ä»»åŠ¡åˆ—è¡¨:\n{}\n\n\
                    è¯·ç»§ç»­: å¦‚æœè¿˜æœ‰æ›´å¤šå­ä»»åŠ¡ï¼Œè¯·ç»§ç»­ä½¿ç”¨ add_todo æ·»åŠ ã€‚\
                    å¦‚æœä»»åŠ¡åˆ—è¡¨å·²å®Œæ•´ï¼Œè¯·ä½¿ç”¨ start_executor å¯åŠ¨æ‰§è¡Œç¬¬ä¸€ä¸ªä»»åŠ¡ã€‚",
                    task_id,
                    description,
                    task_type,
                    self.build_todo_summary()
                );
                self.context
                    .push(MessageBuilder::create_user_message(&feedback, None));
            }
            PlannerAction::StartExecutor { task_id } => {
                println!("ğŸš€ [System] å¯åŠ¨æ‰§è¡Œå™¨ï¼Œä»»åŠ¡ID: {}", task_id);
                self.start_task(&task_id);

                // Add system feedback
                let feedback = format!(
                    "[ç³»ç»Ÿåé¦ˆ] æ‰§è¡Œå™¨å·²å¯åŠ¨ï¼Œæ­£åœ¨æ‰§è¡Œä»»åŠ¡: {}\n\
                    æ‰§è¡Œå™¨å°†è‡ªåŠ¨è¿è¡Œï¼Œå®Œæˆåä¼šè‡ªåŠ¨æ‰§è¡Œä¸‹ä¸€ä¸ªä»»åŠ¡ã€‚",
                    task_id
                );
                self.context
                    .push(MessageBuilder::create_user_message(&feedback, None));
            }
            PlannerAction::PauseExecutor => {
                println!("â¸ï¸ [System] æš‚åœæ‰§è¡Œå™¨");
                self.executor.enqueue(ExecutorCommand::Pause);
            }
            PlannerAction::ResumeExecutor => {
                println!("â–¶ï¸ [System] æ¢å¤æ‰§è¡Œå™¨");
                self.executor.enqueue(ExecutorCommand::Resume);
            }
            PlannerAction::InjectPrompt { content } => {
                // Check executor status and provide appropriate feedback
                let executor_status = self.executor.status().clone();
                let was_stopped = matches!(
                    executor_status,
                    ExecutorStatus::Completed | ExecutorStatus::Idle
                );

                if was_stopped {
                    println!("ğŸ’‰ [System] æ³¨å…¥æç¤ºè¯å¹¶å”¤é†’æ‰§è¡Œå™¨: {}", content);
                    println!(
                        "   â„¹ï¸  æ‰§è¡Œå™¨ä¹‹å‰çŠ¶æ€: {:?}, ç°åœ¨å°†ç»§ç»­æ‰§è¡Œ",
                        executor_status
                    );
                } else {
                    println!("ğŸ’‰ [System] æ³¨å…¥æç¤ºè¯: {}", content);
                }

                // Auto-learn: record this correction for the current task type
                // Look for the most recently active task if no running task
                let task_info = self
                    .todo_list
                    .current_running()
                    .or_else(|| self.todo_list.last_completed())
                    .map(|t| (t.task_type.clone(), t.id.clone(), t.description.clone()));

                if let Some((task_type, task_id, task_desc)) = task_info {
                    let context = Some(format!("ä»»åŠ¡: {} - {}", task_id, task_desc));
                    self.prompt_memory
                        .add_correction(&task_type, &content, context);

                    // Check if we should consolidate corrections
                    let correction_count = self.prompt_memory.pending_corrections(&task_type);
                    if correction_count >= 3 {
                        println!(
                            "ğŸ“š [System] æ£€æµ‹åˆ° {} æ¡çº åè®°å½•ï¼Œå°†è‡ªåŠ¨æ•´åˆåˆ°è®°å¿†ä¸­...",
                            correction_count
                        );
                        // Schedule consolidation (will be done async)
                        self.pending_consolidation_task_types
                            .push(task_type.clone());
                    }

                    // Save memory
                    if let Some(path) = &self.config.prompt_memory_path {
                        let _ = self.prompt_memory.save(path);
                    }

                    // If executor was stopped, re-mark the task as running
                    if was_stopped {
                        if let Some(task) = self.todo_list.get_mut(&task_id) {
                            task.start(); // Re-mark as running
                        }
                    }
                }

                self.executor
                    .enqueue(ExecutorCommand::InjectPrompt { content });
            }
            PlannerAction::ResetExecutor => {
                println!("ğŸ”„ [System] é‡ç½®æ‰§è¡Œå™¨");
                self.executor.enqueue(ExecutorCommand::ResetContext);
            }
            PlannerAction::CompleteTodo { task_id } => {
                if let Some(task) = self.todo_list.get_mut(&task_id) {
                    task.complete();
                    println!("âœ… [System] ä»»åŠ¡å®Œæˆ: {}", task_id);
                }
            }
            PlannerAction::FailTodo { task_id, reason } => {
                if let Some(task) = self.todo_list.get_mut(&task_id) {
                    task.fail(&reason);
                    println!("âŒ [System] ä»»åŠ¡å¤±è´¥: {} - {}", task_id, reason);
                }
            }
            PlannerAction::Report { message } => {
                println!("ğŸ“¢ [Planner] {}", message);
                tracing::info!("Planner report: {}", message);
            }
            PlannerAction::Wait => {
                println!("â³ [Planner] ç­‰å¾…ä¸­...");
            }
            PlannerAction::Done { message } => {
                println!("ğŸ‰ [Planner] è§„åˆ’å®Œæˆ: {}", message);
                tracing::info!("Planner done: {}", message);
            }
        }
    }

    /// Collect executor feedback with history limit.
    fn collect_executor_feedback(&mut self, feedback: ExecutorFeedback) {
        self.executor_feedback_history.push_back(feedback);

        // Enforce history limit
        while self.executor_feedback_history.len() > self.config.max_executor_feedback_history {
            self.executor_feedback_history.pop_front();
        }
    }

    /// Get the prompt memory.
    pub fn prompt_memory(&self) -> &PromptMemory {
        &self.prompt_memory
    }

    /// Get mutable prompt memory.
    pub fn prompt_memory_mut(&mut self) -> &mut PromptMemory {
        &mut self.prompt_memory
    }

    /// Save prompt memory to disk.
    pub fn save_prompt_memory(&self) -> Result<(), crate::agent::prompt_memory::PromptMemoryError> {
        if let Some(path) = &self.config.prompt_memory_path {
            self.prompt_memory.save(path)
        } else {
            Ok(())
        }
    }

    /// Get executor feedback history.
    pub fn feedback_history(&self) -> &VecDeque<ExecutorFeedback> {
        &self.executor_feedback_history
    }

    /// Clear feedback history.
    pub fn clear_feedback_history(&mut self) {
        self.executor_feedback_history.clear();
    }
}

#[cfg(test)]
mod tests {
    use super::*;

    #[test]
    fn test_planner_config_default() {
        let config = PlannerConfig::default();
        assert_eq!(config.max_executor_feedback_history, 2);
        assert_eq!(config.stuck_threshold, 3);
        assert_eq!(config.lang, "cn");
    }

    #[test]
    fn test_planner_config_builder() {
        let config = PlannerConfig::default()
            .with_max_feedback_history(5)
            .with_stuck_threshold(4)
            .with_lang("en");

        assert_eq!(config.max_executor_feedback_history, 5);
        assert_eq!(config.stuck_threshold, 4);
        assert_eq!(config.lang, "en");
    }

    #[test]
    fn test_parse_planner_action_json() {
        let planner_config = PlannerConfig::default();
        let executor_model_config = ModelConfig::default();
        let executor_agent_config = AgentConfig::default();
        let planner =
            PlannerAgent::new(planner_config, executor_model_config, executor_agent_config);

        let json = r#"{"action": "add_todo", "description": "Test task", "task_type": "general"}"#;
        let action = planner.parse_planner_action(json);

        assert!(matches!(action, Some(PlannerAction::AddTodo { .. })));
    }
}
